<div align="center">
  <h1>Antonio Sabbatella</h1>
  <h3>MSc Data Science (110L/110) | AI Research Engineer</h3>

  <p>
    Specializing in <b>Bayesian Optimization</b>, <b>Multi-Agent Systems</b>, and <b>Efficient LLM Architectures</b>.
    <br>
    Bridging the gap between theoretical research and production-grade engineering.
  </p>

  <a href="https://www.linkedin.com/in/AntonioSabbatella">
    <img src="https://img.shields.io/badge/LinkedIn-Connect-blue?style=for-the-badge&logo=linkedin" />
  </a>
  <a href="mailto:antonio.sabbatella.project@gmail.com">
    <img src="https://img.shields.io/badge/Email-Contact-D14836?style=for-the-badge&logo=gmail&logoColor=white" />
  </a>
  <a href="https://scholar.google.com/citations?user=2OhpFQsAAAAJ&hl=en">
    <img src="https://img.shields.io/badge/Google_Scholar-Publications-4285F4?style=for-the-badge&logo=google-scholar&logoColor=white" />
  </a>
</div>

---

### üî¨ Research & Engineering Focus

I focus on **reducing computational overhead** and **automating complex reasoning** in Generative AI systems. My work spans from architectural optimization to high-level agentic orchestration.

* **Deep Learning & Systems:** Designing scalable architectures for **DeepSeek Sparse Attention**, RAG pipelines, and custom execution environments for agentic workflows.
* **Bayesian Optimization:** Automating prompt engineering and multi-agent team composition (MALBO, BOInG) using Multi-Objective strategies.
* **Efficient NLP:** Exploring **Context Compression** frameworks ($84\%$ token reduction) and fine-tuning strategies to optimize inference costs on constrained budgets.

---

### üõ† Tech Stack

**Core:**
![Python](https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=flat-square&logo=pytorch&logoColor=white)
![CUDA](https://img.shields.io/badge/CUDA-76B900?style=flat-square&logo=nvidia&logoColor=white)

**LLM & Agents:**
![HuggingFace](https://img.shields.io/badge/HuggingFace-FFD21E?style=flat-square&logo=huggingface&logoColor=black)
![LangChain](https://img.shields.io/badge/LangChain-1C3C3C?style=flat-square&logo=langchain&logoColor=white)
![BoTorch](https://img.shields.io/badge/BoTorch-Optimization-blue?style=flat-square)

**Infrastructure:**
![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat-square&logo=docker&logoColor=white)
![GCP](https://img.shields.io/badge/Google_Cloud-4285F4?style=flat-square&logo=google-cloud&logoColor=white)
![KNIME](https://img.shields.io/badge/KNIME-Analytics-FFCC00?style=flat-square&logo=knime&logoColor=black)
![Git](https://img.shields.io/badge/Git-F05032?style=flat-square&logo=git&logoColor=white)

---

### üèÜ Featured Work

| Project | Domain | Impact |
| :--- | :--- | :--- |
| **[LUDUS](https://github.com/AntonioSabbatellaUni/LUDUS)** | **Deep Learning / Kernels** | Implementation of **DeepSeek Sparse Attention** for Qwen models. Reduces complexity to $O(N \cdot K)$. Optimized for consumer hardware (T4). |
| **[MALBO](https://github.com/AntonioSabbatellaUni/LLM-Multi-Agent-Optimization-Framework)** | **Multi-Agent / Bayesian Opt** | **Pareto-Efficient Multi-Agent Optimization.** Finds optimal trade-offs between Cost and Performance for agent teams using Multi-Objective Bayesian Optimization. Features a **custom fork of `smolagents`** for heterogeneous LLM swapping. |
| **[StudyWithWisp](https://www.studywithwisp.me)** | **Full Stack AI / SaaS** | AI Platform for student prep (Flashcards/Simulations). Built with **Next.js & Python on GCP**. Scalable RAG pipeline with Prisma. (Private Repo) |
| **[UiNav](https://github.com/AntonioSabbatellaUni/uinav)** | **Computer Vision / Agents** | Autonomous UI interaction system combining **YOLO (finetuned)** with LLMs for natural language-driven browser automation. |

---

### üìÑ Selected Publications

* **[High Impact] Prompt optimization in large language models**
  *A. Sabbatella, A. Ponti, I. Giordani, A. Candelieri, F. Archetti (2024)*
  <br>
  *Mathematics 12 (6), 929*
  <br>
  Seminal work on Bayesian strategies for prompt engineering. Cited by **50+ researchers**.
  <br>
  [![Citations](https://img.shields.io/badge/Citations-52-brightgreen?style=flat-square)](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2OhpFQsAAAAJ&citation_for_view=2OhpFQsAAAAJ:u5HHmVD_uO8C)
  [![DOI](https://img.shields.io/badge/DOI-10.3390%2Fmath12060929-blue?style=flat-square)](https://doi.org/10.3390/math12060929)

* **MALBO: Optimizing LLM-Based Multi-Agent Teams via Multi-Objective Bayesian Optimization**
  *Antonio Sabbatella (2025)*
  <br>
  *arXiv preprint arXiv:2511.11788*
  <br>
  Framework for identifying Pareto-efficient agent teams, achieving **65.8% cost reduction** vs baselines.
  <br>
  [![arXiv](https://img.shields.io/badge/arXiv-2511.11788-b31b1b.svg?style=flat-square)](https://arxiv.org/abs/2511.11788)
  [![Code](https://img.shields.io/badge/Code-MALBO-black?logo=github&style=flat-square)](https://github.com/AntonioSabbatellaUni/LLM-Multi-Agent-Optimization-Framework)

* **Bayesian Optimization for Instruction Generation**
  *A. Sabbatella, et al. (2024)*
  <br>
  *Applied Sciences 14 (24), 11865*
  <br>
  Introduction of the **BOInG** framework, reducing GPU memory requirements by two orders of magnitude.
  <br>
  [![DOI](https://img.shields.io/badge/DOI-10.3390%2Fapp142411865-blue?style=flat-square)](https://doi.org/10.3390/app142411865)

* **Bayesian Optimization Using Simulation-Based Multiple Information Sources**
  *A. Sabbatella, et al. (2024)*
  <br>
  *Machine Learning and Knowledge Extraction 6 (4)*
  <br>
  Advanced combinatorial optimization using multi-source information fusion.
  <br>
  [![Citations](https://img.shields.io/badge/Citations-8-green?style=flat-square)](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2OhpFQsAAAAJ&citation_for_view=2OhpFQsAAAAJ:9ZlFYXVOiuMC)